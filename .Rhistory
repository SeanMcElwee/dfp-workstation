azrep_1_t <- arizona_republic %>%
html_nodes(css = 'li.hero-list-item') %>%
html_text()
azrep_1_l <- arizona_republic %>%
html_nodes(css = 'li.hero-list-item a.hero-list-anchor') %>%
html_attr("href")
azrep_2_t <- arizona_republic %>%
html_nodes(css = 'li.hgpm-item span.hgpm-list-hed') %>%
html_text()
azrep_2_l <- arizona_republic %>%
html_nodes(css = 'li.hgpm-item a.hgpm-link') %>%
html_attr("href")
azrep <- data.frame(
"article" = c(azrep_1_t,azrep_2_t),
"url" = paste0("https://www.azcentral.com",c(azrep_1_l, azrep_2_l)),
"source" = "Arizona Republic",
"state"="AZ",
"date_written" = as.Date(str_extract(paste0("www.azcentral.com",c(azrep_1_l, azrep_2_l)), "\\d{4}/\\d{2}/\\d{2}")),
"date_retrieved" = Sys.time()
)
# ===== Arizona Capitol Times =====
arizona_capitol_times <- read_html("https://azcapitoltimes.com/")
azcap_t <- arizona_capitol_times %>%
html_nodes(css = ".post-thumbnail a") %>%
html_attr("title") %>%
str_replace("Permalink to ", "")
azcap_l <- arizona_capitol_times %>%
html_nodes(css = ".post-thumbnail a") %>%
html_attr("href")
azcap <- data.frame(
"article" = azcap_t,
"url" = azcap_l,
"source" = "Arizona Capitol Times",
"state"="AZ",
"date_written" = as.Date(str_extract(azcap_l, "\\d{4}/\\d{2}/\\d{2}")),
"date_retrieved" = Sys.time()
)
# ===== Los Angeles Times =====
los_angeles_times <- read_html("http://www.latimes.com/politics/")
latim_t_1 <- los_angeles_times %>%
html_nodes(css = ".card .card-content a") %>%
html_text()
latim_l_1 <- los_angeles_times %>%
html_nodes(css = ".card .card-content a") %>%
html_attr("href")
latim_1 <- data.frame(
"article"=gsub("^\\s+|\\s+$", "", latim_t_1),
"url"=latim_l_1,
"source"="Los Angeles Times",
"state"="CA",
"date_written"= as.Date(str_extract(latim_l_1, "\\d{8}"), format = "%Y%m%d"),
"date_retrieved" = Sys.time()
)
latim_1_exclude <- !str_detect(latim_1$article, "[[:alpha:]]+") | str_detect(latim_1$url, "http") | str_detect(latim_1$url, "#nt=footer|byline|tertiarynavbar|taxonomy") | str_detect(latim_1$article, "California politics news feed")
latim_1 <- latim_1[!latim_1_exclude, ]
latim_1 <- unique(latim_1)
los_angeles_times_essential <- read_html("http://www.latimes.com/politics/essential/la-pol-ca-essential-politics-updates-2018-htmlstory.html")
latim_t_2 <- los_angeles_times_essential %>%
html_nodes(css = ".card-content h3 a") %>%
html_text()
latim_l_2 <- los_angeles_times_essential %>%
html_nodes(css = ".card-content h3 a") %>%
html_attr("href")
latim_d_2 <- los_angeles_times_essential %>%
html_nodes(css = ".card-content h6") %>%
html_text()
latim_2 <- data.frame(
"article"=latim_t_2,
"url"=latim_l_2,
"source"="Los Angeles Times",
"state"="CA",
"date_written"= NA,
"date_retrieved" = Sys.time()
)
latim_2_exclude <- str_detect(latim_2$article, "Sign up for our newsletters|Subscribe for unlimited access")
latim_2 <- latim_2[!latim_2_exclude, ]
latim_2$date_written <- as.Date(str_extract(latim_d_2, ".*,.*,"), "%b. %d, %Y,")
latim <- rbind(latim_1, latim_2)
latim$url <- paste0("https://www.latimes.com", latim$url)
latim <- unique(latim)
# ===== Sacramento Bee =====
sacramento_bee <- read_html("http://www.sacbee.com/news/politics-government/")
scbee_t <- sacramento_bee %>%
html_nodes(css = "#story-list .teaser h4.title a") %>%
html_text()
scbee_l <- sacramento_bee %>%
html_nodes(css = "#story-list .teaser h4.title a") %>%
html_attr("href")
scbee <- data.frame(
"article"=scbee_t,
"url"=scbee_l,
"source"="Sacramento Bee",
"state"="CA",
"date_written"= NA,
"date_retrieved" = Sys.time()
)
# ===== San Francisco Chronicle =====
san_francisco_chronicle <- read_html("https://www.sfgate.com/politics/")
sfchr_t <- san_francisco_chronicle %>%
html_nodes(css = "h5 a.hdn-analytics") %>%
html_text()
sfchr_l <- san_francisco_chronicle %>%
html_nodes(css = "h5 a.hdn-analytics") %>%
html_attr("href")
sfchr <- data.frame(
"article"=sfchr_t,
"url"=paste0("https://www.sfgate.com",sfchr_l),
"source"="San Francisco Chronicle",
"state"="CA",
"date_written"= NA,
"date_retrieved" = Sys.time()
)
sfchr <- sfchr[str_detect(sfchr$url, "/politics"), ]
sfchr <- unique(sfchr)
# ===== San Diego Union-Tribune =====
san_diego_union_tribune <- read_html("http://www.sandiegouniontribune.com/news/politics/")
san_diego_union_tribune %>%
html_nodes(css = "h2 a") %>%
html_attr("href")
sdunt_t <- san_diego_union_tribune %>%
html_nodes(css = "h3.trb_outfit_relatedListTitle a") %>%
html_text()
sdunt_l <- san_diego_union_tribune %>%
html_nodes(css = "h3.trb_outfit_relatedListTitle a") %>%
html_attr("href")
sdunt <- data.frame(
"article"=sdunt_t,
"url"=paste0("http://www.sandiegouniontribune.com",sdunt_l),
"source"="San Diego Union-Tribune",
"state"="CA",
"date_written"= as.Date(str_extract(sdunt_l, "\\d{8}"), format = "%Y%m%d"),
"date_retrieved" = Sys.time()
)
# ===== KSTV =====
kstv <- read_html("http://mycn2.com/politics")
kstv_t <- kstv %>%
html_nodes(css = ".article h4 a") %>%
html_text()
kstv_l <- kstv %>%
html_nodes(css = ".article h4 a") %>%
html_attr("href")
kstv_d <- kstv %>%
html_nodes(css = ".article p.published") %>%
html_text()
kstv <- data.frame(
"article"=kstv_t,
"url"=kstv_l,
"source"="KSTV",
"state"="KY",
"date_written"=as.Date(str_extract(kstv_d, "\\d{2}/\\d{2}/\\d{4}"), format = "%m/%d/%Y"),
"date_retrieved" = Sys.time()
)
# ===== Lexington Herald Leader =====
lexington_herald_leader <- read_html("http://www.kentucky.com/news/politics-government/")
lxhrl_t <- lexington_herald_leader %>%
html_nodes(css = ".teaser h4") %>%
html_text()
lxhrl_l <- lexington_herald_leader %>%
html_nodes(css = ".teaser h4 a") %>%
html_attr("href")
lxhrl <- data.frame(
"article"=lxhrl_t,
"url"=lxhrl_l,
"source"="Lexington Herald Leader",
"state"="KY",
"date_written"=NA,
"date_retrieved" = Sys.time()
)
louisville_courier_journal <- read_html("https://www.courier-journal.com/news/politics/")
luvcj_1_t <- louisville_courier_journal %>%
html_nodes(css = 'li.hero-list-item') %>%
html_text()
luvcj_1_l <- louisville_courier_journal %>%
html_nodes(css = 'li.hero-list-item a.hero-list-anchor') %>%
html_attr("href")
luvcj_2_t <- louisville_courier_journal %>%
html_nodes(css = 'li.hgpm-item span.hgpm-list-hed') %>%
html_text()
luvcj_2_l <- louisville_courier_journal %>%
html_nodes(css = 'li.hgpm-item a.hgpm-link') %>%
html_attr("href")
luvcj <- data.frame(
"article" = c(luvcj_1_t,luvcj_2_t),
"url" = paste0("https://www.courier-journal.com/",c(luvcj_1_l, luvcj_2_l)),
"source" = "Louisville Courier Journal",
"state"="KY",
"date_written" = as.Date(str_extract(paste0("https://www.courier-journal.com/",c(luvcj_1_l, luvcj_2_l)), "\\d{4}/\\d{2}/\\d{2}")),
"date_retrieved" = Sys.time()
)
# ===== Salt Lake Tribune =====
salt_lake_tribune <- read_html("https://www.sltrib.com/news/politics/")
sltrb_t <- salt_lake_tribune %>%
html_nodes(css = ".subsection-feed h2") %>%
html_text()
sltrb_l <- salt_lake_tribune %>%
html_nodes(css = ".subsection-feed a") %>%
html_attr("href")
sltrb <- data.frame(
"article"=sltrb_t,
"url"=paste0("https://www.sltrib.com",sltrb_l),
"source"="Salt Lake Tribune",
"state"="UT",
"date_written"=as.Date(str_extract(sltrb_l, "\\d{4}/\\d{2}/\\d{2}"), format = "%Y/%m/%d"),
"date_retrieved" = Sys.time()
)
#deseret_news <- read_html("https://www.deseretnews.com/news/politics")
#deseret_news %>%
#  html_nodes(css = "div.title") %>%
#  html_text()
articles <- do.call(rbind, list(
azrep, azcap, # arizona
latim, scbee, sfchr, sdunt, # california
kstv, lxhrl, luvcj, # kentucky
sltrb # utah
)
)
library(rvest)
library(stringr)
# ===== Arizona Republic =====
arizona_republic <- read_html("https://www.azcentral.com/politics/")
azrep_1_t <- arizona_republic %>%
html_nodes(css = 'li.hero-list-item') %>%
html_text()
azrep_1_l <- arizona_republic %>%
html_nodes(css = 'li.hero-list-item a.hero-list-anchor') %>%
html_attr("href")
azrep_2_t <- arizona_republic %>%
html_nodes(css = 'li.hgpm-item span.hgpm-list-hed') %>%
html_text()
azrep_2_l <- arizona_republic %>%
html_nodes(css = 'li.hgpm-item a.hgpm-link') %>%
html_attr("href")
azrep <- data.frame(
"article" = c(azrep_1_t,azrep_2_t),
"url" = paste0("https://www.azcentral.com",c(azrep_1_l, azrep_2_l)),
"source" = "Arizona Republic",
"state"="AZ",
"date_written" = as.Date(str_extract(paste0("www.azcentral.com",c(azrep_1_l, azrep_2_l)), "\\d{4}/\\d{2}/\\d{2}")),
"date_retrieved" = Sys.time()
)
# ===== Arizona Capitol Times =====
arizona_capitol_times <- read_html("https://azcapitoltimes.com/")
azcap_t <- arizona_capitol_times %>%
html_nodes(css = ".post-thumbnail a") %>%
html_attr("title") %>%
str_replace("Permalink to ", "")
azcap_l <- arizona_capitol_times %>%
html_nodes(css = ".post-thumbnail a") %>%
html_attr("href")
azcap <- data.frame(
"article" = azcap_t,
"url" = azcap_l,
"source" = "Arizona Capitol Times",
"state"="AZ",
"date_written" = as.Date(str_extract(azcap_l, "\\d{4}/\\d{2}/\\d{2}")),
"date_retrieved" = Sys.time()
)
# ===== Los Angeles Times =====
los_angeles_times <- read_html("http://www.latimes.com/politics/")
latim_t_1 <- los_angeles_times %>%
html_nodes(css = ".card .card-content a") %>%
html_text()
latim_l_1 <- los_angeles_times %>%
html_nodes(css = ".card .card-content a") %>%
html_attr("href")
latim_1 <- data.frame(
"article"=gsub("^\\s+|\\s+$", "", latim_t_1),
"url"=latim_l_1,
"source"="Los Angeles Times",
"state"="CA",
"date_written"= as.Date(str_extract(latim_l_1, "\\d{8}"), format = "%Y%m%d"),
"date_retrieved" = Sys.time()
)
latim_1_exclude <- !str_detect(latim_1$article, "[[:alpha:]]+") | str_detect(latim_1$url, "http") | str_detect(latim_1$url, "#nt=footer|byline|tertiarynavbar|taxonomy") | str_detect(latim_1$article, "California politics news feed")
latim_1 <- latim_1[!latim_1_exclude, ]
latim_1 <- unique(latim_1)
los_angeles_times_essential <- read_html("http://www.latimes.com/politics/essential/la-pol-ca-essential-politics-updates-2018-htmlstory.html")
latim_t_2 <- los_angeles_times_essential %>%
html_nodes(css = ".card-content h3 a") %>%
html_text()
latim_l_2 <- los_angeles_times_essential %>%
html_nodes(css = ".card-content h3 a") %>%
html_attr("href")
latim_d_2 <- los_angeles_times_essential %>%
html_nodes(css = ".card-content h6") %>%
html_text()
latim_2 <- data.frame(
"article"=latim_t_2,
"url"=latim_l_2,
"source"="Los Angeles Times",
"state"="CA",
"date_written"= NA,
"date_retrieved" = Sys.time()
)
latim_2_exclude <- str_detect(latim_2$article, "Sign up for our newsletters|Subscribe for unlimited access")
latim_2 <- latim_2[!latim_2_exclude, ]
latim_2$date_written <- as.Date(str_extract(latim_d_2, ".*,.*,"), "%b. %d, %Y,")
latim <- rbind(latim_1, latim_2)
latim$url <- paste0("https://www.latimes.com", latim$url)
latim <- unique(latim)
# ===== Sacramento Bee =====
sacramento_bee <- read_html("http://www.sacbee.com/news/politics-government/")
scbee_t <- sacramento_bee %>%
html_nodes(css = "#story-list .teaser h4.title a") %>%
html_text()
scbee_l <- sacramento_bee %>%
html_nodes(css = "#story-list .teaser h4.title a") %>%
html_attr("href")
scbee <- data.frame(
"article"=scbee_t,
"url"=scbee_l,
"source"="Sacramento Bee",
"state"="CA",
"date_written"= NA,
"date_retrieved" = Sys.time()
)
# ===== San Francisco Chronicle =====
san_francisco_chronicle <- read_html("https://www.sfgate.com/politics/")
sfchr_t <- san_francisco_chronicle %>%
html_nodes(css = "h5 a.hdn-analytics") %>%
html_text()
sfchr_l <- san_francisco_chronicle %>%
html_nodes(css = "h5 a.hdn-analytics") %>%
html_attr("href")
sfchr <- data.frame(
"article"=sfchr_t,
"url"=paste0("https://www.sfgate.com",sfchr_l),
"source"="San Francisco Chronicle",
"state"="CA",
"date_written"= NA,
"date_retrieved" = Sys.time()
)
sfchr <- sfchr[str_detect(sfchr$url, "/politics"), ]
sfchr <- unique(sfchr)
# ===== San Diego Union-Tribune =====
san_diego_union_tribune <- read_html("http://www.sandiegouniontribune.com/news/politics/")
san_diego_union_tribune %>%
html_nodes(css = "h2 a") %>%
html_attr("href")
sdunt_t <- san_diego_union_tribune %>%
html_nodes(css = "h3.trb_outfit_relatedListTitle a") %>%
html_text()
sdunt_l <- san_diego_union_tribune %>%
html_nodes(css = "h3.trb_outfit_relatedListTitle a") %>%
html_attr("href")
sdunt <- data.frame(
"article"=sdunt_t,
"url"=paste0("http://www.sandiegouniontribune.com",sdunt_l),
"source"="San Diego Union-Tribune",
"state"="CA",
"date_written"= as.Date(str_extract(sdunt_l, "\\d{8}"), format = "%Y%m%d"),
"date_retrieved" = Sys.time()
)
# ===== KSTV =====
kstv <- read_html("http://mycn2.com/politics")
kstv_t <- kstv %>%
html_nodes(css = ".article h4 a") %>%
html_text()
kstv_l <- kstv %>%
html_nodes(css = ".article h4 a") %>%
html_attr("href")
kstv_d <- kstv %>%
html_nodes(css = ".article p.published") %>%
html_text()
kstv <- data.frame(
"article"=kstv_t,
"url"=kstv_l,
"source"="KSTV",
"state"="KY",
"date_written"=as.Date(str_extract(kstv_d, "\\d{2}/\\d{2}/\\d{4}"), format = "%m/%d/%Y"),
"date_retrieved" = Sys.time()
)
# ===== Lexington Herald Leader =====
lexington_herald_leader <- read_html("http://www.kentucky.com/news/politics-government/")
lxhrl_t <- lexington_herald_leader %>%
html_nodes(css = ".teaser h4") %>%
html_text()
lxhrl_l <- lexington_herald_leader %>%
html_nodes(css = ".teaser h4 a") %>%
html_attr("href")
lxhrl <- data.frame(
"article"=lxhrl_t,
"url"=lxhrl_l,
"source"="Lexington Herald Leader",
"state"="KY",
"date_written"=NA,
"date_retrieved" = Sys.time()
)
louisville_courier_journal <- read_html("https://www.courier-journal.com/news/politics/")
luvcj_1_t <- louisville_courier_journal %>%
html_nodes(css = 'li.hero-list-item') %>%
html_text()
luvcj_1_l <- louisville_courier_journal %>%
html_nodes(css = 'li.hero-list-item a.hero-list-anchor') %>%
html_attr("href")
luvcj_2_t <- louisville_courier_journal %>%
html_nodes(css = 'li.hgpm-item span.hgpm-list-hed') %>%
html_text()
luvcj_2_l <- louisville_courier_journal %>%
html_nodes(css = 'li.hgpm-item a.hgpm-link') %>%
html_attr("href")
luvcj <- data.frame(
"article" = c(luvcj_1_t,luvcj_2_t),
"url" = paste0("https://www.courier-journal.com",c(luvcj_1_l, luvcj_2_l)),
"source" = "Louisville Courier Journal",
"state"="KY",
"date_written" = as.Date(str_extract(paste0("https://www.courier-journal.com/",c(luvcj_1_l, luvcj_2_l)), "\\d{4}/\\d{2}/\\d{2}")),
"date_retrieved" = Sys.time()
)
# ===== Salt Lake Tribune =====
salt_lake_tribune <- read_html("https://www.sltrib.com/news/politics/")
sltrb_t <- salt_lake_tribune %>%
html_nodes(css = ".subsection-feed h2") %>%
html_text()
sltrb_l <- salt_lake_tribune %>%
html_nodes(css = ".subsection-feed a") %>%
html_attr("href")
sltrb <- data.frame(
"article"=sltrb_t,
"url"=paste0("https://www.sltrib.com",sltrb_l),
"source"="Salt Lake Tribune",
"state"="UT",
"date_written"=as.Date(str_extract(sltrb_l, "\\d{4}/\\d{2}/\\d{2}"), format = "%Y/%m/%d"),
"date_retrieved" = Sys.time()
)
#deseret_news <- read_html("https://www.deseretnews.com/news/politics")
#deseret_news %>%
#  html_nodes(css = "div.title") %>%
#  html_text()
articles <- do.call(rbind, list(
azrep, azcap, # arizona
latim, scbee, sfchr, sdunt, # california
kstv, lxhrl, luvcj, # kentucky
sltrb # utah
)
)
png(filename = "rental.png", width = 5 * diff(states@bbox[,1]), height = 5 * diff(states@bbox[,2]), units = "px")
produce_map(expand_rental, "Mean.Success", font = "Arial")
dev.off()
library(ggplot2)
library(rgdal)
library(maptools)
library(ggmap)
library(scales)
setwd("~/Desktop/Data For Progress/US Mapping/")
# load in function to load census fips data
source("load_census_fips.R")
# load census fips data
load_census_fips()
# load in the csv
expand_rental <- read.csv("data/expand_rental.csv")
# join it into the census basetable
expand_rental <- plyr::join(census_fips, expand_rental)
fixup <- function(usa,alaskaFix,hawaiiFix){
alaska=usa[usa$NAME=="Alaska",]
alaska = prelim_fix(alaska,alaskaFix)
proj4string(alaska) <- proj4string(usa)
hawaii = usa[usa$NAME=="Hawaii",]
hawaii = prelim_fix(hawaii,hawaiiFix)
proj4string(hawaii) <- proj4string(usa)
usa = usa[! usa$NAME %in% c("Alaska","Hawaii"),]
usa = rbind(usa,alaska,hawaii)
return(usa)
}
prelim_fix <- function(object,params){
r=params[1];scale=params[2];shift=params[3:4]
object = elide(object,rotate=r)
size = max(apply(bbox(object),1,diff))/scale
object = elide(object,scale=size)
object = elide(object,shift=shift)
object
}
# tranformations
states <- readOGR(dsn = "cb_2017_us_state_20m",layer="cb_2017_us_state_20m_2")
states <- subset(states, NAME %in% census_fips$name)
states <- spTransform(states, CRS("+init=epsg:2163"))
#states = fixup(states,c(-35,1.8,-2800000,-2600000),c(-35,1,6800000,-1600000))
states <- fixup(states, c(-35,1.75,-3500000,-2000000),c(-35,1,4500000,-1200000))
states <- spTransform(states, CRS("+init=epsg:4326"))
plot(states)
id_lookup <- data.frame("id"=rownames(states@data), "STUSPS"=states@data$STUSPS)
nationwide <- unionSpatialPolygons(states, rep(1,length(states)))
states_f <- fortify(states)
states_f$abbr <- id_lookup[match(states_f$id, id_lookup$id),]$STUSPS
nationwide <- fortify(nationwide)
produce_map <- function(states_data, column, title=NULL, subtitle=NULL, font="Verdana"){
states <- plyr::join(states_f, states_data)
ggplot() +
geom_polygon(data=nationwide, aes(x=long, y=lat, group=group), fill = NA, color = "black", size = 1.25) +
geom_polygon(data=states, aes(x=long, y=lat, group=group, fill = get(column)/100), color = "white", size = 0.075) +
scale_fill_gradientn(name = "", label=percent, colors=c("#ff8000","#FFFFFF","#006600"),
guide = guide_colorbar(direction = "horizontal", barheight = 0.6, ticks = FALSE, barwidth = 45),
limits = c(0.2,0.8), na.value = "#006600") +
coord_map() +
labs(title = title, subtitle = toupper(subtitle)) +
theme(
panel.background = element_blank(),
plot.title = element_text(hjust = 0.5, size = 24),
plot.subtitle = element_text(hjust = 0.5, size = 16, face = "bold"),
text = element_text(family = font),
legend.position="bottom",
axis.title.y=element_blank(),
axis.text.y=element_blank(),
axis.ticks.y=element_blank(),
axis.title.x=element_blank(),
axis.text.x=element_blank(),
axis.ticks.x=element_blank()
)
}
png(filename = "rental.png", width = 5 * diff(states@bbox[,1]), height = 5 * diff(states@bbox[,2]), units = "px")
produce_map(expand_rental, "Mean.Success", font = "Arial")
dev.off()
